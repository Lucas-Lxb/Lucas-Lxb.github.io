<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Lucas-Lxb">
    
    <title>
        
            MikPoly-编译优化论文解读 |
        
        Lucas-Lxb&#39;s Blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    
        <link rel="shortcut icon" href="/images/author.svg">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.1/font/css/fontawesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.1/font/css/regular.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.1/font/css/solid.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.1/font/css/brands.min.css">
    
        
            
                
<link rel="stylesheet" href="/css/custom-1.css">
<link rel="stylesheet" href="/css/custom-2.css">

            
        
    
    <script class="keep-theme-configurations">
    const KEEP = window.KEEP || {}
    KEEP.hexo_config = {"hostname":"lucas-lxb.github.io","root":"/","language":"zh-CN","path":"search.json"}
    KEEP.theme_config = {"base_info":{"primary_color":"#0066cc","title":"Lucas-Lxb's Blog","author":"Lucas-Lxb","avatar":"/images/author.svg","logo":"/images/author.svg","favicon":"/images/author.svg","mode":"dark"},"menu":{"home":"/                        || fa-solid fa-home","archives":"/archives            || fa-solid fa-box-archive","tags":"/tags                    || fa-solid fa-tags","categories":"/categories        || fa-solid fa-layer-group","about":"/about                || fa-solid fa-user-graduate"},"first_screen":{"enable":true,"background_img":"/images/bg.svg","background_img_dark":"/images/bg.svg","description":null,"hitokoto":true},"social_contact":{"enable":true,"links":{"github":"https://github.com/Lucas-Lxb","weixin":"img | ./images/wechat.jpg","qq":null,"weibo":null,"zhihu":null,"twitter":null,"x":null,"facebook":null,"email":"15176106029@163.com"}},"scroll":{"progress_bar":false,"percent":false,"hide_header":true},"home":{"announcement":null,"category":true,"tag":true,"post_datetime":"updated","post_datetime_format":"YYYY-MM-DD"},"post":{"author_badge":{"enable":false,"level_badge":false,"custom_badge":null},"word_count":{"wordcount":true,"min2read":true},"datetime_format":"YYYY-MM-DD HH:mm:ss","copyright_info":true,"share":true,"created_datetime_icon":"fa-solid fa-star","updated_datetime_icon":"fa-solid fa-arrows-rotate","reward":{"enable":false,"img_link":null,"text":null}},"code_block":{"tools":{"enable":true,"style":"default"},"highlight_theme":"default"},"toc":{"enable":true,"number":false,"expand_all":true,"init_open":true,"layout":"right"},"website_count":{"busuanzi_count":{"enable":false,"site_uv":true,"site_pv":true,"page_pv":true}},"local_search":{"enable":true,"preload":true},"comment":{"enable":false,"use":null,"valine":{"appid":null,"appkey":null,"server_urls":null,"placeholder":null},"gitalk":{"github_id":"Lucas-Lxb","github_admins":null,"repository":"blog-talks","client_id":"Ov23li5UjEmaXBGbwEPU","client_secret":"2e50a89dabf6cc8bb33b91732d2246fef167c294","proxy":null},"twikoo":{"env_id":null,"region":null,"version":"1.6.36"},"waline":{"server_url":null,"reaction":false,"version":"3.2.1"},"giscus":{"repo":null,"repo_id":null,"category":"Announcements","category_id":null,"reactions_enabled":false},"artalk":{"server":null},"disqus":{"shortname":null}},"rss":{"enable":true},"lazyload":{"enable":true},"cdn":{"enable":true,"provider":"cdnjs"},"pjax":{"enable":false},"footer":{"since":2020,"word_count":false,"site_deploy":{"enable":true,"provider":"github","url":null},"record":{"enable":false,"list":[{"code":null,"link":null}]}},"inject":{"enable":true,"css":[["/css/custom-1.css","/css/custom-2.css"]],"js":[null]},"root":"","source_data":{},"version":"4.2.1"}
    KEEP.language_ago = {"second":"%s 秒前","minute":"%s 分钟前","hour":"%s 小时前","day":"%s 天前","week":"%s 周前","month":"%s 个月前","year":"%s 年前"}
    KEEP.language_code_block = {"copy":"复制代码","copied":"已复制","fold":"折叠代码块","folded":"已折叠"}
    KEEP.language_copy_copyright = {"copy":"复制版权信息","copied":"已复制","title":"原文标题","author":"原文作者","link":"原文链接"}
  </script>
<meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="Keep" type="application/atom+xml">
</head>


<body>
<div class="progress-bar-container">
    

    
</div>



<main class="page-container border-box">
    <!-- home first screen  -->
    

    <!-- page content -->
    <div class="page-main-content border-box">
        <div class="page-main-content-top">
            
<header class="header-wrapper">

    <div class="border-box header-content">
        <div class="left flex-start border-box">
            
                <a class="logo-image border-box" href="/">
                    <img src="/images/author.svg">
                </a>
            
            <a class="site-name border-box" href="/">
               Lucas-Lxb&#39;s Blog
            </a>
        </div>

        <div class="right border-box">
            <div class="pc border-box">
                <ul class="menu-list border-box">
                    
                        
                        <li class="menu-item flex-start border-box">
                            <a class="menu-text-color border-box" href="/">
                                
                                    <i class="menu-text-color menu-icon fa-solid fa-home"></i>
                                
                                首页
                                
                            </a>
                            
                        </li>
                    
                        
                        <li class="menu-item flex-start border-box">
                            <a class="menu-text-color border-box" href="/archives">
                                
                                    <i class="menu-text-color menu-icon fa-solid fa-box-archive"></i>
                                
                                归档
                                
                            </a>
                            
                        </li>
                    
                        
                        <li class="menu-item flex-start border-box">
                            <a class="menu-text-color border-box" href="/tags">
                                
                                    <i class="menu-text-color menu-icon fa-solid fa-tags"></i>
                                
                                标签
                                
                            </a>
                            
                        </li>
                    
                        
                        <li class="menu-item flex-start border-box">
                            <a class="menu-text-color border-box" href="/categories">
                                
                                    <i class="menu-text-color menu-icon fa-solid fa-layer-group"></i>
                                
                                分类
                                
                            </a>
                            
                        </li>
                    
                        
                        <li class="menu-item flex-start border-box">
                            <a class="menu-text-color border-box" href="/about">
                                
                                    <i class="menu-text-color menu-icon fa-solid fa-user-graduate"></i>
                                
                                关于
                                
                            </a>
                            
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="menu-text-color fas search fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile border-box flex-start">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list border-box">
            
                
                <li class="drawer-menu-item border-box not-sub-menu">
                    <label class="drawer-menu-label border-box">
                        <a class="drawer-menu-text-color left-side flex-start border-box" href="/">
                            
                                <span class="menu-icon-wrap border-box flex-center">
                                    <i class="drawer-menu-text-color menu-icon fa-solid fa-home"></i>
                                </span>
                            
                            首页
                        </a>
                        
                    </label>
                    
                </li>
            
                
                <li class="drawer-menu-item border-box not-sub-menu">
                    <label class="drawer-menu-label border-box">
                        <a class="drawer-menu-text-color left-side flex-start border-box" href="/archives">
                            
                                <span class="menu-icon-wrap border-box flex-center">
                                    <i class="drawer-menu-text-color menu-icon fa-solid fa-box-archive"></i>
                                </span>
                            
                            归档
                        </a>
                        
                    </label>
                    
                </li>
            
                
                <li class="drawer-menu-item border-box not-sub-menu">
                    <label class="drawer-menu-label border-box">
                        <a class="drawer-menu-text-color left-side flex-start border-box" href="/tags">
                            
                                <span class="menu-icon-wrap border-box flex-center">
                                    <i class="drawer-menu-text-color menu-icon fa-solid fa-tags"></i>
                                </span>
                            
                            标签
                        </a>
                        
                    </label>
                    
                </li>
            
                
                <li class="drawer-menu-item border-box not-sub-menu">
                    <label class="drawer-menu-label border-box">
                        <a class="drawer-menu-text-color left-side flex-start border-box" href="/categories">
                            
                                <span class="menu-icon-wrap border-box flex-center">
                                    <i class="drawer-menu-text-color menu-icon fa-solid fa-layer-group"></i>
                                </span>
                            
                            分类
                        </a>
                        
                    </label>
                    
                </li>
            
                
                <li class="drawer-menu-item border-box not-sub-menu">
                    <label class="drawer-menu-label border-box">
                        <a class="drawer-menu-text-color left-side flex-start border-box" href="/about">
                            
                                <span class="menu-icon-wrap border-box flex-center">
                                    <i class="drawer-menu-text-color menu-icon fa-solid fa-user-graduate"></i>
                                </span>
                            
                            关于
                        </a>
                        
                    </label>
                    
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle border-box">

            <div class="main-content border-box">
                

                    
<div class="fade-in-down-animation">
    <div class="post-page-container border-box">
        <div class="post-content-container border-box">
            

            <div class="post-content-bottom border-box">
                
                    <div class="post-title">
                        MikPoly-编译优化论文解读
                    </div>
                

                
                    <div class="post-header border-box">
                        
                            <div class="avatar-box border-box">
                                <img src="/images/author.svg">
                            </div>
                        
                        <div class="info-box">
                            <div class="author border-box">
                                <span class="name">Lucas-Lxb</span>
                                
                            </div>
                            <div class="meta-info border-box">
                                

<div class="post-meta-info-container border-box post">
    <div class="post-meta-info border-box">
        

        
            <span class="meta-info-item post-create-date">
                <i class="icon fa-solid fa-star"></i>&nbsp;
                <span class="datetime">2024-10-15 15:24:45</span>
            </span>

            <span class="meta-info-item post-update-date">
                <i class="icon fa-solid fa-arrows-rotate"></i>&nbsp;
                <span class="datetime" data-updated="Tue Oct 15 2024 15:26:33 GMT+0800">2024-10-15 15:26:33</span>
            </span>
        

        

        
            <span class="post-tag meta-info-item border-box">
                <ul class="post-tag-ul">
                    
                            <li class="tag-item"><span class="tag-separator"><i class="icon fas fa-hashtag"></i></span><a href="/tags/%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96/">编译优化</a></li>
                        
                    
                </ul>
            </span>
        

        
        
            <span class="meta-info-item post-wordcount">
                <i class="icon fas fa-file-word"></i>&nbsp;<span>8.9k 字</span>
            </span>
        
        
            <span class="meta-info-item post-min2read">
                <i class="icon fas fa-clock"></i>&nbsp;<span>33 分钟</span>
            </span>
        
        
    </div>

    
</div>

                            </div>
                        </div>
                    </div>
                

                <div class="post-content keep-markdown-body ">
                    

                    
                         <h1 style="text-align: center;">    Optimizing Dynamic-Shape Neural Networks on
Accelerators via On-the-Fly Micro-Kernel
Polymerization </h1>
<h1 style="text-align: center;">   （基于微核聚合的加速器动态形状神经网络优化） </h1>
<h1>一、涉及到的定义</h1>
<h2 id="1-计算图">1.计算图</h2>
<p>计算图是神经网络中的一组算子及其数据依赖关系的表示，用于描述神经网络的前向和反向传播过程</p>
<p>（1）计算图的类型：</p>
<ul>
<li>
<p>静态计算图</p>
<p>在执行前先构建完整的计算图，然后通过给定的输入数据反复执行，计算图一旦定义，不能在运行过程中修改。</p>
</li>
</ul>
<p>​			提前构建计算图后可以进行优化，如内存优化、操作融合等，能提高执行效率。适合推理阶段的高效执行</p>
<ul>
<li>
<p>动态计算图</p>
<p>在执行过程中动态构建计算图，每次前向传播时计算图都会重新生成，因此可以根据具体的输入动态调整网络结构</p>
<p>​	相比静态图，动态图在某些场景下的性能优化空间较小，特别是在推理阶段，性能可能略逊，原因如图下：</p>
<ol>
<li>由于静态图的计算图在运行前就已经完整定义，因而框架可以从全局视角对图进行分析和优化，包括使用数据流分析、并行化处理、内存分配优化等复杂的优化操作</li>
<li>由于动态图需要在每次在还行模型时动态生成，因而在优化时无法站在全局的视角，只能逐步构建，违法进行跨层操作融合</li>
<li>动态图可以处理更加灵活的控制流结构（如 if 语句），但是因此也会带来额外的计算开销</li>
</ol>
</li>
</ul>
<p>（2）为什么可以动态构建计算图？</p>
<ol>
<li>
<p><strong>操作即构建</strong>：</p>
<p>在 PyTorch 等框架中，计算图是在执行过程中通过每一步的操作动态构建的。例如，当你定义一个线性层操作或卷积层时，并不会立即创建整个计算图，而是在输入数据真正传递到该层时，框架会即时构建与这一操作相关的计算节点。</p>
</li>
<li>
<p><strong>计算图依赖于输入数据</strong>：</p>
<p>动态图的计算不仅依赖于模型的结构，还依赖于输入数据的形状和内容。例如，递归神经网络（RNN）等网络在处理不定长的输入时，每次执行前向传播可能需要生成不同的计算图。</p>
</li>
<li>
<h4 id="执行与定义合二为一："><strong>执行与定义合二为一</strong>：</h4>
<p>在动态图框架中，<strong>计算图的定义与执行是一体的</strong>。每当执行一个操作，框架就在内部即时创建对应的计算图节点，并执行该操作。因此，计算图并不是预先定义好的，而是随代码的执行动态生成和处理。</p>
</li>
<li>
<p><strong>控制流</strong>：</p>
<p>在动态图中，你可以使用 Python 中的控制流结构（如 <code>if</code> 语句或 <code>for</code> 循环）来动态改变网络的行为。因此，计算图并不是在模型定义时完全固定的，而是可以根据输入和条件语句在运行时动态调整。</p>
</li>
</ol>
<h2 id="2-循环平铺结构">2.循环平铺结构</h2>
<p>将大循环分解成小块，使得每块的数据能够有效地放入CPU缓存中，减少对主存的访问次数 有助于提高局部性，因为缓存比主存的访问速度更快</p>
<p>例子：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> N 1024</span></span><br><span class="line"><span class="type">double</span> A[N][N], B[N][N], C[N][N];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">matrix_multiply</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; M; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; N; j++) &#123;</span><br><span class="line">            C[i][j] = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">0</span>; k &lt; K; k++) &#123;</span><br><span class="line">                C[i][j] += A[i][k] * B[k][j];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>应用循环平铺的版本：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> N 1024</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> TILE_SIZE 32 <span class="comment">// 假设这是一个合适的平铺大小</span></span></span><br><span class="line"><span class="type">double</span> A[N][N], B[N][N], C[N][N];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">tiled_matrix_multiply</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; M; i += TILE_SIZE) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; N; j += TILE_SIZE) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">0</span>; k &lt; K; k += TILE_SIZE) &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> ii = i; ii &lt; i + TILE_SIZE; ii++) &#123;</span><br><span class="line">                    <span class="keyword">for</span> (<span class="type">int</span> jj = j; jj &lt; j + TILE_SIZE; jj++) &#123;</span><br><span class="line">                        <span class="keyword">for</span> (<span class="type">int</span> kk = k; kk &lt; k + TILE_SIZE; kk++) &#123;</span><br><span class="line">                            C[ii][jj] += A[ii][kk] * B[kk][jj];</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1>二、论文全文内容总结</h1>
<h2 id="1-Introduction">1 	Introduction</h2>
<h3 id="三种张量计算的代表性方法">三种张量计算的代表性方法</h3>
<p>该部分首先介绍了现有的三类支持高性能张量计算的代表性方法：</p>
<ul>
<li>供应商提供的自建库</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">硬件平台</th>
<th style="text-align:center">x86 CPUs</th>
<th style="text-align:center">Nvidia GPUs</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">自建库</td>
<td style="text-align:center">oneDNN</td>
<td style="text-align:center">cuBLAS</td>
</tr>
</tbody>
</table>
<p>上述自建库的实际实验效果有限，因为自建库针对特定形状进行优化的操作符实现并不适应所有形状，因而不可避免地导致性能下降。</p>
<p>比如如下所示使用在cuBLAS实现的GEMM例程对于不同的张量形状有显著的性能差异：</p>
<table>
<thead>
<tr>
<th>张量形状（M,N,K）</th>
<th>(4096,4096,4096)</th>
<th>(105,1024,12544)</th>
</tr>
</thead>
<tbody>
<tr>
<td>计算能力</td>
<td>262.2 TFLOPS</td>
<td>22.3 TFLOPS</td>
</tr>
</tbody>
</table>
<ul>
<li>静态形状算子的张量编译器</li>
</ul>
<p>大多数张量编译器，如TensorFlow XLA [29]，TVM [7]和TC [55]，通过<strong>在大量搜索空间内搜索循环平铺结构</strong>来优化张量运算符，以确定给定形状的最佳实现。尽管如此，这些自动编译器在编译期间需要操作者的形状的先验知识。由于广泛搜索空间内的搜索成本很高，这种限制使得在动态场景中跨所有潜在形状优化张量运算符变得不可行。</p>
<ul>
<li>动态形状算子的张量编译器</li>
</ul>
<p>最近，一些研究探索了动态形状编译器[49，65，70]。一个例子是DietCode [65]，它通过优化形状通用搜索空间来增强传统的自动搜索器，以实现最佳操作符。然而，这些动态形状自动生成器仍然依赖于预定义的形状描述和离线代码优化。</p>
<hr>
<h3 id="现有方法弊端和解决方案">现有方法弊端和解决方案</h3>
<p>接下来对现有的方法的弊端进行阐述，并给出MIKPOLY的解决方案：</p>
<ul>
<li>
<p>现有的方法的弊端：利用了处理一系列形状的自动化程序来离线生成优化程序的有限子集。然而，这些自动排序器不能保证对预定义范围之外的形状的有效甚至正确执行，从而限制了它们在具有频繁形状变化的动态场景中的可用性。</p>
</li>
<li>
<p>MIKPOLY的解决方案：创建一组微调的固定大小的微内核，每个微内核代表一个平铺的循环嵌套，负责执行张量运算符的一部分。这些微内核是离线生成的，并动态组合，为模型执行期间遇到的任何张量形状生成优化的代码。关键的挑战在于确定一个有效的组合策略，并在模型执行过程中以非常低的成本生成优化的代码。</p>
</li>
</ul>
<hr>
<h3 id="本文所做的工作">本文所做的工作</h3>
<p>根据该解决方案，文章阐述了本文所做的工作：</p>
<ol>
<li>提出了一个两阶段的方法来生成一个优化的张量程序</li>
<li>引入了一个精确而轻量级的成本模型，有利于高效的在线聚合</li>
<li>在代表性的两个加速器——GPU和NPU上进行测试，效果很好</li>
</ol>
<hr>
<h2 id="2Background-and-Motivation">2	Background and Motivation</h2>
<p>背景：现实世界的应用程序通常表现出动态行为，例如语言建模中不同长度的句子，使得静态形状的神经网络不足。为了解决这一限制，动态形状神经网络已经被提出来支持更复杂的现实世界的智能应用。代表性场景如下：</p>
<ol>
<li>动态批次大小：较大批次会加快参数收敛的速度，并提高模型的稳定性。当前研究者提出动态批次大小的方法，随着训练过程动态调整批次大小，以提升性能和适应真实应用场景</li>
<li>动态图像分辨率：传统的方法会将图像调整为固定尺寸，这样往往会导致信息的丢失，特别是在检测复杂场景中的小目标时。现代方法会通过引入高级池化方法，在不损失图像细节的前提下，提升测量精度。</li>
<li>动态序列长度：在自然语言处理应用中，输入序列的长度是动态变化的，通常的解决方案是将序列填充到固定的最大长度，但是这种填充策略会浪费资源，特别是实际序列长度远小于最大序列长度的时候 ，因而要求使用优化的策略来动态处理序列长度，减少资源浪费，提高计算效率</li>
</ol>
<hr>
<h3 id="现有技术解决算子的实现">现有技术解决算子的实现</h3>
<p><img  
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241006210148999.png"
                        alt="image-20241006210148999"
                 ></p>
<p><img    
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241006210632492.png"
                         alt="image-20241006210632492" style="zoom:50%;" 
                 ><img    
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241006210918987.png"
                         alt="image-20241006210918987" style="zoom: 45%;" 
                 ></p>
<ol>
<li>
<p>静态形状张量编译器（如TVM）：</p>
<ul>
<li>功能：为固定形状的张量（M N K ）生成高效实现，通过枚举不同的平铺大小，找到最佳的配置，从而优化张量操作的性能</li>
<li>问题：需要大量的离线编译时间，且只适用于特定的输入形状，另外在实际的动态形状任务中效率较低</li>
</ul>
</li>
<li>
<p>动态形状张量编译器（如DietCode）：</p>
<ul>
<li>功能：为不同形状生成多个预编译的张量程序，在运行时可以根据输入张量的形状进行选择，从而减少了编译开销</li>
<li>局限性：要求在编译阶段事先了解可能的张量形状范围，从而限制了其应用范围</li>
</ul>
</li>
</ol>
<hr>
<h3 id="Mikpoly解决算子的实现">Mikpoly解决算子的实现</h3>
<h4 id="1-MikPoly-的核心思想">(1)MikPoly 的核心思想</h4>
<ul>
<li><strong>MikPoly</strong> 主要目的是解决动态形状张量运算的挑战，特别是在不同形状的张量运算中保持高性能。</li>
<li>通过一个两阶段的模板流程，MikPoly 在编译阶段生成了一组高度优化的<strong>微内核</strong>，并在运行时根据动态形状选择最优的微内核来执行张量运算。</li>
</ul>
<p><img  
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241006211127609.png"
                        alt="image-20241006211127609"
                 ></p>
<h4 id="2-两阶段流程">(2)两阶段流程</h4>
<ul>
<li><strong>离线阶段</strong>：在编译时，MikPoly 使用静态形状（如 M=4096,N=1024,K=4096）生成一系列的固定尺寸的微内核。这些微内核是通过探索最佳的 tile 参数和循环展开优化而生成的，并针对不同形状进行优化。</li>
<li><strong>在线阶段</strong>：在运行时，当具体的张量形状 M,N,K确定后，MikPoly 动态选择和组合这些预先优化好的微内核，生成最优的张量操作程序。在线阶段探索了不同的微内核组合策略来适应当前形状。</li>
</ul>
<h4 id="3-微内核多样化">(3) 微内核多样化</h4>
<ul>
<li>MikPoly 提供了灵活的微内核生成和组合策略。例如，在离线阶段生成的微内核（如 micro-kernel(a.uM, a.uN, <a class="link"   target="_blank" rel="noopener" href="http://a.uK" >a.uK<i class="fas fa-external-link-alt"></i></a>) 和 micro-kernel(b.uM, b.uN, <a class="link"   target="_blank" rel="noopener" href="http://b.uK" >b.uK<i class="fas fa-external-link-alt"></i></a>)）被灵活地组织在一起，以应对不同的形状变化。</li>
<li><strong>Pattern I</strong> 和 <strong>Pattern II</strong> 是两种不同的微内核聚合模式，它们根据不同的形状和性能需求进行适配选择。</li>
</ul>
<h4 id="4-成本模型的使用">(4)成本模型的使用</h4>
<ul>
<li>MikPoly 使用了一个精确且轻量化的成本模型，在运行时快速评估不同微内核组合的开销，并选择最佳组合，从而确保高效的执行。图中显示，成本模型指导了动态微内核的选择过程。</li>
</ul>
<h4 id="5-最终效果">(5)最终效果</h4>
<ul>
<li>MikPoly 通过这种基于微内核的动态形状优化，有效地提升了动态形状神经网络在现代加速器上的性能，尤其是在形状变化频繁的情况下，MikPoly 显著缩短了编译时间，并且优化了运行效率。</li>
</ul>
<h2 id="3The-MIKPOLY-Design">3	The MIKPOLY Design</h2>
<p><img  
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241006211529544.png"
                        alt="image-20241006211529544"
                 ></p>
<p><strong>Mikpoly的两阶段设计</strong>：微内核生成 (S1) 和微内核聚合 (S2)</p>
<ul>
<li>S1：微内核生成（Offline）：
<ul>
<li>在编译时（离线），MikPoly 使用模板驱动的调优流程生成微内核。</li>
<li>通过自动调度（Auto-Scheduling）来生成一组优化的微内核，每个微内核针对特定尺寸进行优化。</li>
<li>同时开发一个微内核性能模型（Micro-Kernel Performance Model），为每个微内核提供性能预测。</li>
</ul>
</li>
<li>S2：微内核聚合（Online）：
<ul>
<li>在运行时，基于已知的张量形状，MikPoly 通过运行时聚合组件（Runtime Polymerization）对张量操作的程序模板进行重新组织，生成不同的实现。</li>
<li>MikPoly 使用一个轻量级的聚合成本模型（Polymerization Cost Model）选择最佳的微内核组合，以最小化计算开销。</li>
</ul>
</li>
</ul>
<p><strong>微内核生成阶段 (S1) 的工作流程</strong>：</p>
<ul>
<li>MikPoly 首先通过模板驱动生成微内核，并使用自动调度系统对其进行性能调优。</li>
<li>针对不同的尺寸（形状）生成一组高度优化的微内核程序。</li>
<li>该阶段的生成是离线进行的，因此不影响运行时性能。</li>
</ul>
<p><strong>运行时的微内核聚合阶段 (S2)</strong>：</p>
<ul>
<li>MikPoly 在已知张量形状后，通过在运行时重新组织微内核来适应动态形状。</li>
<li>MikPoly 使用轻量级成本模型，动态选择最适合的微内核组合，从而为每个特定的形状找到最佳的执行方案。</li>
<li>这种方法能够在不同形状之间提供高效的切换，同时保持较低的计算开销。</li>
</ul>
<p><strong>多级加速器抽象</strong>：</p>
<ul>
<li>MikPoly 的设计采用了多级加速器抽象（Multi-Level Accelerator Abstraction），将每个计算单元抽象为处理引擎（PE, Processing Engine），并使用局部内存和全局内存来表示不同层次的内存架构。</li>
<li>这种抽象层次有助于 MikPoly 在硬件层面实现高效的资源利用，并提升神经网络的计算性能。</li>
</ul>
<p><strong>启发式策略探索</strong>：</p>
<ul>
<li>MikPoly 还探索了基于启发式的聚合策略，以根据运行时的张量形状选择最佳策略。通过多样化的策略选择，MikPoly 能够在不同的执行环境中高效运行。</li>
</ul>
<p><strong>最终目标</strong>：MikPoly 通过结合离线微内核生成和在线微内核聚合，解决了动态形状张量操作中性能不稳定的问题，能够在现代加速器上显著提高动态形状神经网络的执行性能。</p>
<h3 id="多级加速器抽象">多级加速器抽象</h3>
<p>Mikploy为硬件平台设计了多级加速器抽象，考虑指标$$ H = \left( P_{\text{multi}}, M_{\text{local}}, M_{\text{global}} \right) $$：</p>
<p>$$ ( P_{\text{multi}})$$：硬件中的处理引擎（并行处理的计算单元）的数目（PEs）</p>
<p>$$ ( M_{\text{local}})$$：单个PE内的本地存储器</p>
<p>$$ ( M_{\text{global}})$$：多个PEs之间的共享存储器</p>
<p>一个张量程序在硬件上运行的并行性依赖于$$ P_{\text{multi}}$$，它的内存访问特性（独占或共享）由 $$ M_{\text{local}}$$和$$  M_{\text{global}}$$控制。在可行的情况下，$$ M_{\text{local}}$$用于存储数据，从而提高内存访问效率，而$$ M_{\text{global}}$$在PE之间平均分配带宽。</p>
<p>两款代表性加速器的H指标如下图所示：</p>
<p><img  
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241006214337292.png"
                        alt="image-20241006214337292"
                 ></p>
<h3 id="两阶段优化">两阶段优化</h3>
<p>该部分通过GEMM算子的动态形状优化后张量程序执行过程的例子对MIKPOLY的两阶段优化过程进行阐述。</p>
<h4 id="解耦优化空间">解耦优化空间</h4>
<p>==介绍循环平铺的概念==</p>
<p>将平铺程序模版定义为Q，可将Q分为两个部分：$$ Q{\text{offline}}$$和$$ Q{\text{online}}$$</p>
<p>$$ Q{\text{offline}}$$：专门用来充分利用本地存储器的最内层循环</p>
<p>$$ Q{\text{online}}$$：为优化共享存储器而存在的剩余循环</p>
<h4 id="离线优化空间">离线优化空间</h4>
<p>①使用$$ Q{\text{offline}}$$中的离线循环作为微内核的模版，声明为$$ \hat{K} $$</p>
<p>②通过模版$$ \hat{K} $$，生成一系列具有固定大小的微内核，并且在生成微内核的同时，为每个微内核生成对应的性能模型（在之后的微内核聚合的阶段$$ Q{\text{online}}$$中使用）</p>
<h4 id="在线优化空间">在线优化空间</h4>
<p>①使用预先定义好的聚合模式（GEMM则为表3中的两种模式）为$$ Q{\text{online}}$$（外层循环）重新组织排列方式，再加上前一阶段已经生成完毕的$$ Q{\text{offline}}$$中的微内核集合，一同为Q重新构建具体的实现方式。</p>
<p>②对得到的所有程序<strong>通过探索所有固定大小微内核的聚合策略</strong>实现参数的实例化</p>
<p>③在这些实例化的程序中根据成本模型选取性能最好的程序样例进行导出</p>
<h4 id="优化目标">优化目标</h4>
<p>使用$$ S{\text{s}}$$表示Mikpoly探索得出的所有张量程序的集合，那么寻找最优程序的问题可以被定义为优化问题：<br>
$$<br>
S^* = \arg\min_{S \in S_S} \text{Cost}(S, H)<br>
$$<br>
这个$$\text{Cost}(S, H)$$为本文定义的聚合成本模型，通过并行性、内存访问和资源利用等因素来估计其性能</p>
<h3 id="微内核生成">微内核生成</h3>
<h4 id="自动调整固定大小的微内核">自动调整固定大小的微内核</h4>
<p>将离线优化空间中使用一个模版$$ \hat{K} $$生成的微内核的集合定义为$$S_{\tilde{K}}$$,每个微内核定义为$$\tilde{K}$$</p>
<p>该阶段的运行过程如下：(三个超参数：$$n_{\text{gen}}$$、$$n_{\text{syn}}$$、$n_{\text{mik}}$)</p>
<ol>
<li>根据模版$$ \hat{K} $$生成每维度的平铺大小在$${ 16 \times i \mid i \in [1, n_{\text{gen}}] }$$范围的微内核，将这些微内核统一包含在$$S_{\tilde{K}}$$中</li>
<li>生成一个张量程序，如下：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(dimension_size_1):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(dimension_size_2):</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(dimension_size_3):</span><br><span class="line">            C[i, j] += A[i, k] * B[k, j]</span><br></pre></td></tr></table></figure>
<p>设置张量程序中的三个dimension_size的范围为$${ 2^i \mid i \in [0, n_{\text{syn}}] }$$，得到一系列测试程序</p>
<ol start="3">
<li>使用第一步得到的微内核集合执行这些测试程序，按照运行过程中的平均性能进行排名，保留$\text{Top-}n_{\text{mik}}$的性能表现者</li>
</ol>
<p>在实际的评估结果中，我们选择    $$n_{\text{gen}}$$ = 32 $$n_{\text{syn}}$$ = 12 $n_{\text{mik}}$ = 40     作为实际参数，该组参数能够最小化离线微内核生成和在线聚合的开销</p>
<h4 id="微内核性能模型">微内核性能模型</h4>
<p>在微内核生成的过程中，Mikpoly会为每一个微内核生成一个性能模型，微内核定义为$$\tilde{K} = (uM,uN,uK)$$，性能评估模型定义为$$g_{predict}(t,\tilde{K},H)$$</p>
<p>假设GEMM表示为  (M N K) = (t1 * uM,    t2 *uN,   t3 * uK)</p>
<p><strong>(1)</strong></p>
<p>得到单个$$C[i][j]$$时不能并行化（因为存在数据相关），因而应该在单个PE上执行</p>
<p>（每个$$C[i][j]$$的计算会运行t3个$$\tilde{K}$$的实例）</p>
<p>对单个$$C[i][j]$$的计算采用流水线技术，该技术分为三个阶段 /单个流水线任务可分为三个阶段：</p>
<ol>
<li>$M_{\text{global}}$加载数据到$M_{\text{local}}$</li>
<li>在单个PE上使用微内核$$\tilde{K}$$处理$M_{\text{local}}$的数据（中间结果存储在$M_{\text{local}}$中）</li>
<li>最终将结果从$M_{\text{local}}$写回到$M_{\text{global}}$</li>
</ol>
<p><strong>(2)</strong></p>
<p>各个$$C[i][j]$$之间可通过在多个PE之间并行工作</p>
<p>根据以上GEMM表示形式，如果使用微内核$$\tilde{K} = (uM,uN,uK)$$，则</p>
<p>共有t1 * t2 个流水线任务，PE个数为$$ ( P_{\text{multi}})$$，那么该GEMM算子的执行成本为t1 * t2 / $$ ( P_{\text{multi}})$$个流水线任务的成本</p>
<p><strong>(3)</strong></p>
<p>由于在运行时才会得到 t1 t2 t3,因而只考虑单个流水线任务即可</p>
<p>定义性能模型函数$$g_{predict}(t,\tilde{K},H)$$，设定t∈[1,$$ ( n_{\text{predict}})$$],在平台H上的单个PE上预先运行，得到一系列预先计算好的性能数据( $$  n_{\text{predict}}$$ 一般根据经验设定为 5120 )</p>
<h3 id="微内核聚合">微内核聚合</h3>
<h4 id="聚合模式">聚合模式</h4>
<p>在这个阶段，MIkpoly将$$ Q{\text{online}}$$划分为多个循环嵌套，每个循环嵌套包含相同的微内核$$\tilde{K} $$，但是只处理原始区域的一部分(称为第 $$  R_{\text{i}}$$个区域)</p>
<p>Mikpoly将操作符GEMM的输出分为7块，具体如下图（a）所示，并依据这7块区域的不同组合方式设置出了9种不同的聚合模式。（通过大量的负载评估实验中得到）</p>
<p><img  
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241007141433280.png"
                        alt="image-20241007141433280"
                 ></p>
<h4 id="聚合策略">聚合策略</h4>
<p>使用在离线评估性能在前$\text{Top-}n_{\text{mik}}$的微内核集合的$$S_{\tilde{K}}$$中的微内核和前一步得到的聚合模式对整个聚合程序模版Q进行实例化，并且使用类似于CUTLASS的局部填充技术来最大限度减少边界检查，确保了能够填充任何形状的微内核组合的可能性。</p>
<p>填充技术的原理如下图所示：</p>
<h4 id="image-20241007144016720"><img  
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241007144016720.png"
                        alt="image-20241007144016720"
                 ></h4>
<h4 id="聚合成本模型">聚合成本模型</h4>
<p>该模型考虑因素如下：</p>
<ul>
<li>微内核生成时的性能模型</li>
<li>程序在实际执行过程中的并发性</li>
</ul>
<p>采用的成本模型如下：<br>
$$<br>
\text{Cost}(S, H) = \sum_{(R_i, \tilde{K}<em>i) \in S} f</em>{\text{wave}}(R_i, \tilde{K}<em>i, H) \times f</em>{\text{pipe}}(R_i, \tilde{K}_i, H)<br>
$$</p>
<p>$$<br>
f_{\text{wave}}(R_i, \tilde{K}<em>i, H) = \left\lceil \frac{f</em>{\text{parallel}}(R_i, \tilde{K}<em>i)}{|P</em>{\text{multi}}|} \right\rceil<br>
$$</p>
<p>$$<br>
f_{\text{pipe}}(R_i, \tilde{K}<em>i, H) = g</em>{\text{predict}} \left( f_{\text{num}}(R_i, \tilde{K}_i), \tilde{K}_i, H \right)<br>
$$</p>
<p>其中$f_{\text{pipe}}$是单个流水线任务的执行开销</p>
<p>$f_{\text{wave}}$则是并行执行多个流水线任务的成本（波的次数）</p>
<p>$f_{\text{parallel}}$是流水线任务的个数</p>
<p>$g_{\text{predict}}$是离线阶段得到的性能模型函数</p>
<p>$f_{\text{num}}(R_i, \tilde{K}<em>i)$是在某一嵌套循环$$  R</em>{\text{i}}$$中，一个流水线任务中出现的微内核实例的个数</p>
<h3 id="MIkpoly完整算法实现">MIkpoly完整算法实现</h3>
<img    
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241007150202922.png"
                         alt="image-20241007150202922" style="zoom:50%;" 
                 >
<p><strong>离线生成阶段（Offline Generation）：</strong></p>
<ul>
<li>在这个阶段，优化后的微核 $S_{\tilde{K}}$ 是通过微核模板 $\tilde{K}$ 使用 <strong>TVM</strong> 自动调度器生成的。</li>
</ul>
<p><strong>动态多态化阶段（On-the-Fly Polymerization）：</strong></p>
<ul>
<li>当运行时知道某个动态形状时，<strong>MikPoly</strong> 会尝试应用预定义的模式基于一个两阶段的模板 Q。</li>
<li><strong>MtkPoly</strong> 利用启发式方法来探索多态化策略，并估算代价。</li>
<li>如果 $(R_i, \tilde{K}_i)$ 的成本超过当前最佳策略的成本，那么相关的策略将会被跳过，从而显著缩小搜索空间并减少运行时的开销。</li>
</ul>
<p><strong>最终结果：</strong></p>
<ul>
<li><strong>MtkPoly</strong> 基于最佳的多态化策略，构建了一个优化的张量程序 $S^*$。</li>
</ul>
<h2 id="4-Implementation">4	 Implementation</h2>
<p>本节对不同的加速器平台的实现细节进行阐述。</p>
<h3 id="GPU-平台"><strong>GPU 平台</strong></h3>
<ul>
<li><strong>自动调度器和模板</strong>：
<ul>
<li>对于 GPU，<strong>MtkPoly</strong> 使用 <strong>TVM</strong> 自动调度器结合 <strong>CUTLASS</strong> 模板，生成固定大小的参数化微核。生成的微核被编译成二进制文件，并保持恒定的形状大小，张量的起始地址和循环迭代次数在运行时作为参数动态确定。</li>
</ul>
</li>
<li><strong>动态多态化</strong>：
<ul>
<li>在运行时，<strong>MtkPoly</strong> 基于输入形状选择合适的多态化策略，并实例化对应的微核。对于 GPU，采用了模式 I 和 II，以保持性能与运行时开销之间的最佳平衡。线程块通过 GPU 硬件调度器动态分配给多处理器（SM），避免静态分配。</li>
</ul>
</li>
<li><strong>性能优化</strong>：
<ul>
<li>由于硬件的高效动态调度能力，GPU 上不需要静态分配线程资源，重点在于减少运行时的开销。因此，MtkPoly 仅使用少量预定义的模式（模式 I 和 II），以优化性能和运行时效率。张量地址偏移等信息在运行时传递给微核，并通过标量赋值，确保最小化的开销。</li>
</ul>
</li>
</ul>
<h3 id="NPU-平台"><strong>NPU 平台</strong></h3>
<ul>
<li><strong>手动模板和分配</strong>：
<ul>
<li>对于 NPU，<strong>MtkPoly</strong> 使用手动模板生成固定大小的参数化微核。与 GPU 类似，生成的微核同样编译为二进制文件，并保持恒定的形状大小，同时将张量的起始地址和循环迭代次数作为运行时参数。</li>
</ul>
</li>
<li><strong>动态多态化</strong>：
<ul>
<li>在 NPU 上，MtkPoly 提供了更多的模式选择（模式 I-IX），并使用最大-最小静态分配算法将任务并行化分配到多个计算核心（如 DaVinci Cores）。这些模式为微核在多个处理单元之间的分配提供了灵活性和更高的并行性能。</li>
</ul>
</li>
<li><strong>性能优化</strong>：
<ul>
<li>在 NPU 平台上，由于更注重并行化执行的性能，手动分配的微核使用最大-最小静态分配算法来优化不同核心之间的任务负载分布，以提升整体性能。与 GPU 不同，NPU 的并行化任务需要手动调度和分配，因此 NPU 使用了更多的多态化模式来适应不同的任务。</li>
</ul>
</li>
</ul>
<h2 id="5Evaluation">5	Evaluation</h2>
<p><strong>Mikpoly的目标</strong>：能够有效优化加速器上的动态张量算子和神经网络，表现优于现有的水平</p>
<p>模型评估主要聚焦于两个问题：</p>
<ul>
<li>是否能够优化动态张量算子和神经网络</li>
<li>提出的成本模型是否能够有效地支持微内核聚合</li>
</ul>
<h3 id="实验环境">实验环境</h3>
<p>硬件平台：</p>
<p><img  
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241007154257983.png"
                        alt="image-20241007154257983"
                 ></p>
<p>软件环境：</p>
<table>
<thead>
<tr>
<th>平台</th>
<th>软件环境</th>
<th>性能评估工具</th>
</tr>
</thead>
<tbody>
<tr>
<td>GPU</td>
<td>CUTLASS、CUDA toolkit(with cuBLAS and cuDNN libraries)</td>
<td>Pytorch for CNN models and   TuroTransformers for languanges models</td>
</tr>
<tr>
<td>NPU</td>
<td>CANN SDK</td>
<td>MindSpore</td>
</tr>
</tbody>
</table>
<p>软件解释：</p>
<ul>
<li>cuBLAS and cuDNN在GPU上提供了GEMM和卷积运算的标准基础实现</li>
<li>CUTLASS在GPU上提供了GEMM的模板化实现，用于加速GEMM和卷积运算操作</li>
</ul>
<p>备注：</p>
<ul>
<li>对上述的库中实现卷积操作的操作使用GEMM算子实现</li>
<li>进行实验的预热操作，提前对程序运行20次</li>
</ul>
<h3 id="基准测试">基准测试</h3>
<p>针对GEMM算子和卷积算子进行测试，</p>
<h4 id="测试样例选择">测试样例选择</h4>
<p>GEMM算子：</p>
<img    
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241007161809071.png"
                         alt="image-20241007161809071" style="zoom:50%;" 
                 >
<p>测试样例分别来自百度的基准测试工具DeepBench，和真实世界中出现的GEMM算子的动态形状范围示例（包括基于Transformer的模型和基于CNN的模型）</p>
<p>卷积算子：</p>
<img    
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241007162437941.png"
                         alt="image-20241007162437941" style="zoom:50%;" 
                 >
<p>测试样例取自具有代表性的四类CNN网络模型</p>
<h4 id="测试过程">测试过程</h4>
<p>将基础库（cuBLAS、cuDNN、CANN）中的标准GEMM算子和卷积算子替换成Mikpoly优化后的算子，对四种语言模型和四种CNN网络进行推理性能的测试</p>
<h3 id="性能结果">性能结果</h3>
<h4 id="对动态形状算子的优化效果">对动态形状算子的优化效果</h4>
<h5 id="MIKPOLY-vs-GPU-libraries">MIKPOLY  vs  GPU libraries</h5>
<img    
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241007182705608.png"
                         alt="image-20241007182705608" style="zoom:50%;" 
                 >
<p>该表解读：</p>
<ul>
<li>定性来看：对于GEMM和卷积算子而言，Mikpoly、CUTLASS、cuBLAS（Mikpoly、CUTLASS、cuDNN）中效果最好的为Mikpoly</li>
<li>定量来看：Mikpoly
<ul>
<li>与cuBLAS相比，平均GEMM加速比为1.47倍（最大为4.82倍）</li>
<li>与cuDNN相比，平均卷积加速比为1.98倍（最大为5.38倍）</li>
<li>与CUTLASS相比，平均GEMM加速比和卷积加速比分别为3.02倍和1.72倍</li>
</ul>
</li>
</ul>
<h5 id="MIKPOLY-vs-NPU-libraries">MIKPOLY  vs  NPU libraries</h5>
<img    
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241007184123884.png"
                         alt="image-20241007184123884" style="zoom:50%;" 
                 >
<p>该表解读：</p>
<p>相较于CANN这个NPU厂商提供的自建库，Mikpoly的效果更好。其中GEMM和卷积的加速比分别为 1.10和1.41倍</p>
<h4 id="对动态模型推理的优化效果">对动态模型推理的优化效果</h4>
<p>MiKPOLY对模型推理的延迟 = Mikpoly成本模型的计算时间($$ Q{\text{online}}$$的耗时) + 优化后的算子在加速器上的最终执行时间</p>
<h5 id="GPU上进行模型推理">GPU上进行模型推理</h5>
<p>（四种语言模型和四种CNN网络）</p>
<hr>
<p>测试主体：</p>
<ul>
<li>Mikpoly</li>
<li>CUTLASS</li>
<li>cuBLAS / cuDNN（其效果作为基准线）</li>
</ul>
<hr>
<img    
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241007185056559.png"
                         alt="image-20241007185056559" style="zoom: 33%;" 
                 >
<p>对上述两表的解读：</p>
<ul>
<li>
<p>定性看：Mikpoly的效果在三者中是最好的；</p>
</li>
<li>
<p>定量看：Mikpoly相对于cuBLAS / cuDNN对四种语言模型的加速比分别为1.39、1.38、1.36、1.37</p>
</li>
</ul>
<p>​			  Mikpoly相对于cuBLAS / cuDNN对四种CNN模型的加速比分别为1.34、1.69、1.52、1.22</p>
<h5 id="NPU上进行模型推理">NPU上进行模型推理</h5>
<p>和CANN相比，Mikpoly在四种CNN网络中的平均加速比为1.30、1.19、1.32、1.38</p>
<h4 id="Mikpoly和现有技术对比">Mikpoly和现有技术对比</h4>
<p>所比较对象：</p>
<ul>
<li>
<p>Mikpoly</p>
</li>
<li>
<p>现有的动态形状张量编译器 DietCode、Nimble</p>
</li>
<li>
<p>厂商自建库CUTLASS</p>
</li>
</ul>
<hr>
<p>测试样例取自前文使用GEMM算子的1433个测试案例</p>
<p>测试结果如下表所示：</p>
<img    
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241007191409254.png"
                         alt="image-20241007191409254" style="zoom: 67%;" 
                 >
<p>根据该表，Mikpoly相比于DietCode、Nimble、CUTLASS的加速比分别为2.94、7.54、3.59</p>
<hr>
<p>深入测试：测试四种语言模型的模型推理性能，实验结果如下表所示：</p>
<p><img  
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241007191908960.png"
                        alt="image-20241007191908960"
                 ></p>
<p>通过该表得到Mikpoly相较于剩余三种工具中性能最优的DietCode的加速比平均为1.55</p>
<hr>
<p>根据实验得到的差异进行分析：因为动态编译器预先定义好了动态形状的变化范围，因为当实际的形状超出了它所定义的范围时，程序会因为越界错误或者资源不可用导致无效的错误。</p>
<p>下面使用实验验证分析的正确性：</p>
<p><img  
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241007193619670.png"
                        alt="image-20241007193619670"
                 ></p>
<p>根据上表，当预先设定DietCode输入范围为128、512、1024、2048、8192时，在整个的8192个测试样例中，其有效执行次数始终没有Mikpoly效果好，另外假设测试样例的范围就是DietCode的预先设定值时，它的运行效果仍旧没有Mikpoly效果好，这一点可通过下表得到。</p>
<p><img  
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241007193955181.png"
                        alt="image-20241007193955181"
                 ></p>
<h4 id="将Mikpoly应用到大语言模型LLM">将Mikpoly应用到大语言模型LLM</h4>
<p>在这部分文章选用LLM的一个版本——Llama2-13b</p>
<p>对比主体：</p>
<ul>
<li>Mikpoly</li>
<li>Faster Transformer(专门针对英伟达GPU的模型加速推理工具)</li>
</ul>
<p>测试结果：</p>
<p><img  
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241007195259250.png"
                        alt="image-20241007195259250"
                 ></p>
<p>通过上表可以得到：在不同的batch size(1、2、4、8)和不同的输入序列长度下，Mikpoly相较于</p>
<p>Faster Transformer的平均加速比为1.05  1.04  1.02  1.01</p>
<h3 id="性能分析">性能分析</h3>
<p>该部分对GEMM算子在GPU上的完整性能进行分析</p>
<h4 id="在线聚合开销">在线聚合开销</h4>
<img    
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241007200203416.png"
                         alt="image-20241007200203416" style="zoom:50%;" 
                 >
<p>通过该表可知，Mikpoly在这三种GEMM实现工具中的总体运行时间是最短的（以cuBLAS为基线）</p>
<p>另外，Mikpoly中的聚合成本（红色部分）占其总体运行成本的一小部分，并且由于高效的成本模型，这部分成本随着形状的增大而减少</p>
<h4 id="成本模型有效性">成本模型有效性</h4>
<p>为了证明成本模型的有效性，提出了三种Mikpoly的变体：</p>
<ul>
<li>Mikpoly-ORACLE      在动态聚合阶段采用穷举搜索，最终只计算优化后的程序的运行时间，不考虑动态聚合时的时间成本</li>
<li>Mikpoly-WAVE           尽可能减少并行度，因而容易产生大尺寸的微内核</li>
<li>Mikpoly-PIPE             最大化单个流水线任务的性能，容易产生小尺寸的微内核</li>
</ul>
<p>对以上三种变体，再加上Mikpoly和CUTLASS一共五个测试主体（以Mikpoly-ORACLE 为基线），测试得到如下结果：</p>
<img    
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241007202631144.png"
                         alt="image-20241007202631144" style="zoom:67%;" 
                 >
<p>实验结果：</p>
<p>相较于Mikpoly-ORACLE，Mikpoly、Mikpoly-WAVE、Mikpoly-PIPE的加速比分别为0.96、0.81、0.72</p>
<p>结果分析：</p>
<ol>
<li>
<p>Mikpoly考虑了减少并行度和最大化单个流水线任务的性能，因而在Mikpoly、Mikpoly-WAVE、Mikpoly-PIPE中性能最好。</p>
</li>
<li>
<p>虽然Mikpoly-ORACLE的运行时性能最好，但是在线聚合阶段由于其采用了穷举搜索的方法，因而根据给定的动态形状到最终产生合适的聚合策略的时间长达1.6秒，而Mikpoly则只需要2微秒；同时从最终的运行时间看，Mikpoly-ORACLE只计算运行时的时间和Mikpoly聚合时间加上优化后程序运行时间大致相同，这说明了成本模型的有效性</p>
</li>
</ol>
<h3 id="超参数分析">超参数分析</h3>
<p>本部分对前文在离线阶段微内核生成时涉及到的三个超参数进行探讨</p>
<p><img  
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241007205101231.png"
                        alt="image-20241007205101231"
                 ></p>
<p>通过该表可以得到，随着三个超参数的增加，Mikpoly相对于cuBLAS的加速比逐渐上升，并最终达到饱和点，根据该图得到三个超参数的最终设置的值</p>
<h2 id="6-Case-Studies">6 	Case Studies</h2>
<p>在这部分探讨微内核聚合有效性的根本原因——提高了硬件利用率、缓解了负载不均衡的问题</p>
<p>该部分考虑动态形状(M N K) = (4096,1024,4096),使用以下三种微内核组合对该算子进行优化：</p>
<ul>
<li>$\text{GEMM-A}$</li>
<li>$\text{GEMM-B}$</li>
<li>$\text{GEMM-AB}$</li>
</ul>
<img    
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241007212611574.png"
                         alt="image-20241007212611574" style="zoom:50%;" 
                 >
<p>通过上图可以得到，$\text{GEMM-A}$的执行时间较$\text{GEMM-B}$更短，以下采用$\text{GEMM-A}$来和$\text{GEMM-AB}$进行对比。</p>
<p>在GPU上分别对这两种微内核组合进行测试，使用GPU的性能分析工具测试相关的测试指标，得到的结果如下：</p>
<img    
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241007212934061.png"
                         alt="image-20241007212934061" style="zoom:50%;" 
                 >
<p>性能指标解释：</p>
<ul>
<li>
<p>sm_efficiency%：一个SM（流式处理器）上至少有一个wrap（线程组）处于活动状态的时间百分比</p>
</li>
<li>
<p>elapsed_cycles_sm:每个SM上的始终周期数</p>
</li>
<li>
<p>grid_size:为GEMM任务分配的线程块的数量</p>
</li>
</ul>
<p>通过该表可知，在采用微内核聚合之后，sm的利用率上升，并且单个sm的时钟周期数目降低（任务完成时间减少了），这样就提高了硬件的利用率，最终的效果自然也就更好了</p>
<hr>
<p>除了使用性能评估工具对相关指标进行测试外，文章还对两种组合优化后的程序在实际硬件中的运行轨迹进行了建模，使用理论计算得出微内核聚合对负载不均衡的缓解问题。</p>
<p>理论计算过程如下：</p>
<ol>
<li>
<p>使用GPU型号为A100，它含有108个SM，每个SM最多容纳64个wrap;</p>
</li>
<li>
<p>在实际的运行过程中，两个kernel（$\text{GEMM-A}$、$\text{GEMM-B}$）对SM的占用率只有1 / 8，为8 wrap / SM;</p>
</li>
<li>
<p>108 * 8 = 864，即每个波次该GPU只能处理864个wrap;</p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">对于GEMM-A =(256,128,32)：</span><br><span class="line"></span><br><span class="line">单个流水线任务需要256个线程的线程块（8 wrap）;</span><br><span class="line">一共所需要的流水线任务数目为（4096 * 1024） / （256 * 128） = 128个；</span><br><span class="line">则最终需要128 * 8 = 1024个wrap,需要 1024 / 864 = 2个波次才能完成</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">对于GEMM-AB：</span><br><span class="line"></span><br><span class="line">按照模式二将GEMM算子划分为两部分：</span><br><span class="line">- （3072 1024 4096）    使用GEMM-A =(256,128,32)</span><br><span class="line">- （1024 1024 4096）    使用GEMM-B =(64,64,64)</span><br><span class="line"></span><br><span class="line">第一部分:</span><br><span class="line">	由于使用GEMM-A，单个流水线任务需要256个线程的线程块（8 wrap）;</span><br><span class="line">	一共所需要的流水线任务数目为（3072 * 1024） / （256 * 128） = 96个；</span><br><span class="line">	则需要96 * 8 = 768个wrap</span><br><span class="line">第二部分:</span><br><span class="line">	由于使用GEMM-B，单个流水线任务需要128个线程的线程块（4 wrap）;</span><br><span class="line">	一共所需要的流水线任务数目为（1024 * 1024） / （64 * 64） = 256个；</span><br><span class="line">	则需要256 * 4 = 1024个wrap</span><br><span class="line"></span><br><span class="line">将两部分进行加和，得到最终需要768 + 1024 = 1792个wrap,为1792 / 864 = 3个波次完成</span><br></pre></td></tr></table></figure>
<p>对上述的计算过程进行绘图，得到下图：</p>
<p><img  
                       lazyload
                       alt="image"
                       data-src="https://cdn.jsdelivr.net/gh/Lucas-Lxb/pictures-picgo/img/image-20241007221221233.png"
                        alt="image-20241007221221233"
                 ></p>
<p>根据该图，可以得到两个组合的执行时间分别为 (2 * Ta)  和  (Ta + 2 * Tb)</p>
<p>其中Ta、Tb分别表示两个内核组合执行单个流水线任务的时间。</p>
<p>在Ta &gt; 2 * Tb时，微内核聚合相对于单个微内核的效果为(2 * Ta) / (Ta + 2 * Tb) 倍。</p>
<h2 id="7-Discussion">7	 Discussion</h2>
<h3 id="通用性">通用性</h3>
<p>在GPU/NPU上对GEMM/卷积算子和语言模型和CNN网络的加速效果好</p>
<h3 id="适用性">适用性</h3>
<ol>
<li>对输入形状在较大范围内频繁变化时的操作符表现良好</li>
<li>在编译时已知某些输入形状的范围时，可通过更加合适的微内核集合的生成来细化成本模型，最终实现更好的优化来增强性能</li>
</ol>
<h3 id="限制">限制</h3>
<ul>
<li>计划探索MikPoly与图级优化技术的结合，例如算子融合，以进一步增强动态形状场景中图级的性能</li>
<li>当前的实现使用基于GEMM的卷积方法，研究其他卷积实现有潜在的好处，例如Winograd，它可能会提供额外的性能改进</li>
</ul>

                    
                </div>

                
                        
<div class="post-copyright-info-container border-box">
    <div class="copyright-info-content border-box">
        <div class="copyright-info-top border-box">
            <div class="copyright-post-title border-box text-ellipsis">
                MikPoly-编译优化论文解读
            </div>

            <div class="copyright-post-link border-box text-ellipsis">
                2024/10/15/MikPoly/
            </div>
        </div>

        <div class="copyright-info-bottom border-box">
            <div class="copyright-post-author bottom-item">
                <div class="type">
                    作者
                </div>
                <div class="content">Lucas-Lxb</div>
            </div>

            <div class="post-time bottom-item">
                <div class="type">
                    发布于
                </div>
                <div class="content">2024-10-15 15:24</div>
            </div>


            <div class="post-license bottom-item">
                <div class="type">
                    许可
                </div>
                <div class="content tooltip" data-tooltip-content="CC BY-NC-SA 4.0">
                    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh-hans" target="_blank">
                        
                            <i class="fa-brands fa-creative-commons"></i>
                            <i class="fa-brands fa-creative-commons-by"></i>
                            <i class="fa-brands fa-creative-commons-nc"></i>
                            <i class="fa-brands fa-creative-commons-sa"></i>
                        
                    </a>
                </div>
            </div>
        </div>

        <i class="copyright-bg fa-solid fa-copyright"></i>
    </div>
    <div class="copy-copyright-info flex-center tooltip" data-tooltip-content="复制版权信息" data-tooltip-offset-y="-2px">
        <i class="fa-solid fa-copy"></i>
    </div>
</div>

                

                <div class="post-bottom-tags-and-share border-box">
                    <div>
                        
                            <ul class="post-tags-box border-box">
                                
                                    <li class="tag-item border-box">
                                        <i class="icon fas fa-hashtag"></i>&nbsp;<a href="/tags/%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96/">编译优化</a>
                                    </li>
                                
                            </ul>
                        
                    </div>
                    <div>
                        
                            <div class="post-share-container border-box">
    <ul class="share-list-wrap border-box">
        <li class="qq share-item border-box flex-center tooltip"
            data-tooltip-content="分享到 QQ"
        >
            <i class="fa-brands fa-qq"></i>
        </li>
        <li class="wechat share-item border-box flex-center tooltip tooltip-img"
            data-tooltip-content="分享到微信"
            data-tooltip-img-tip="微信扫一扫"
            data-tooltip-img-style="background-color: #fff; top: -10px; padding: 0.6rem 0.6rem 0.1rem 0.6rem;"
        >
            <i class="fa-brands fa-weixin"></i>
        </li>
        <li class="weibo share-item border-box flex-center tooltip"
            data-tooltip-content="分享到微博"
        >
            <i class="fa-brands fa-weibo"></i>
        </li>
    </ul>
</div>

                        
                    </div>
                </div>

                

                
                    <div class="post-nav border-box">
                        
                        
                            <div class="next-post">
                                <a class="next"
                                   rel="next"
                                   href="/2024/09/07/RPC_communciation_mechanism%20on%20TVM/"
                                   title="RPC_communciation_mechanism on TVM"
                                >
                                    <span class="title flex-center">
                                        <span class="post-nav-title-item text-ellipsis">RPC_communciation_mechanism on TVM</span>
                                        <span class="post-nav-item">下一篇</span>
                                    </span>
                                    <span class="right arrow-icon flex-center">
                                        <i class="fas fa-chevron-right"></i>
                                    </span>
                                </a>
                            </div>
                        
                    </div>
                

                
                    






                
            </div>
        </div>

        
            <div class="pc-post-toc right-toc">
                <div class="post-toc-wrap border-box">
    <div class="post-toc border-box">
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-text">    Optimizing Dynamic-Shape Neural Networks on
Accelerators via On-the-Fly Micro-Kernel
Polymerization </span></a></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-text">   （基于微核聚合的加速器动态形状神经网络优化） </span></a></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-text">一、涉及到的定义</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E8%AE%A1%E7%AE%97%E5%9B%BE"><span class="nav-text">1.计算图</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%A7%E8%A1%8C%E4%B8%8E%E5%AE%9A%E4%B9%89%E5%90%88%E4%BA%8C%E4%B8%BA%E4%B8%80%EF%BC%9A"><span class="nav-text">执行与定义合二为一：</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E5%BE%AA%E7%8E%AF%E5%B9%B3%E9%93%BA%E7%BB%93%E6%9E%84"><span class="nav-text">2.循环平铺结构</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-text">二、论文全文内容总结</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Introduction"><span class="nav-text">1 	Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E7%A7%8D%E5%BC%A0%E9%87%8F%E8%AE%A1%E7%AE%97%E7%9A%84%E4%BB%A3%E8%A1%A8%E6%80%A7%E6%96%B9%E6%B3%95"><span class="nav-text">三种张量计算的代表性方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%8E%B0%E6%9C%89%E6%96%B9%E6%B3%95%E5%BC%8A%E7%AB%AF%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="nav-text">现有方法弊端和解决方案</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%AC%E6%96%87%E6%89%80%E5%81%9A%E7%9A%84%E5%B7%A5%E4%BD%9C"><span class="nav-text">本文所做的工作</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2Background-and-Motivation"><span class="nav-text">2	Background and Motivation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%8E%B0%E6%9C%89%E6%8A%80%E6%9C%AF%E8%A7%A3%E5%86%B3%E7%AE%97%E5%AD%90%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-text">现有技术解决算子的实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Mikpoly%E8%A7%A3%E5%86%B3%E7%AE%97%E5%AD%90%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-text">Mikpoly解决算子的实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-MikPoly-%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3"><span class="nav-text">(1)MikPoly 的核心思想</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%B5%81%E7%A8%8B"><span class="nav-text">(2)两阶段流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E5%BE%AE%E5%86%85%E6%A0%B8%E5%A4%9A%E6%A0%B7%E5%8C%96"><span class="nav-text">(3) 微内核多样化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-%E6%88%90%E6%9C%AC%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-text">(4)成本模型的使用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-%E6%9C%80%E7%BB%88%E6%95%88%E6%9E%9C"><span class="nav-text">(5)最终效果</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3The-MIKPOLY-Design"><span class="nav-text">3	The MIKPOLY Design</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E7%BA%A7%E5%8A%A0%E9%80%9F%E5%99%A8%E6%8A%BD%E8%B1%A1"><span class="nav-text">多级加速器抽象</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%A4%E9%98%B6%E6%AE%B5%E4%BC%98%E5%8C%96"><span class="nav-text">两阶段优化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%A7%A3%E8%80%A6%E4%BC%98%E5%8C%96%E7%A9%BA%E9%97%B4"><span class="nav-text">解耦优化空间</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A6%BB%E7%BA%BF%E4%BC%98%E5%8C%96%E7%A9%BA%E9%97%B4"><span class="nav-text">离线优化空间</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9C%A8%E7%BA%BF%E4%BC%98%E5%8C%96%E7%A9%BA%E9%97%B4"><span class="nav-text">在线优化空间</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BC%98%E5%8C%96%E7%9B%AE%E6%A0%87"><span class="nav-text">优化目标</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BE%AE%E5%86%85%E6%A0%B8%E7%94%9F%E6%88%90"><span class="nav-text">微内核生成</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%87%AA%E5%8A%A8%E8%B0%83%E6%95%B4%E5%9B%BA%E5%AE%9A%E5%A4%A7%E5%B0%8F%E7%9A%84%E5%BE%AE%E5%86%85%E6%A0%B8"><span class="nav-text">自动调整固定大小的微内核</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BE%AE%E5%86%85%E6%A0%B8%E6%80%A7%E8%83%BD%E6%A8%A1%E5%9E%8B"><span class="nav-text">微内核性能模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BE%AE%E5%86%85%E6%A0%B8%E8%81%9A%E5%90%88"><span class="nav-text">微内核聚合</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%81%9A%E5%90%88%E6%A8%A1%E5%BC%8F"><span class="nav-text">聚合模式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%81%9A%E5%90%88%E7%AD%96%E7%95%A5"><span class="nav-text">聚合策略</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#image-20241007144016720"><span class="nav-text"></span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%81%9A%E5%90%88%E6%88%90%E6%9C%AC%E6%A8%A1%E5%9E%8B"><span class="nav-text">聚合成本模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MIkpoly%E5%AE%8C%E6%95%B4%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0"><span class="nav-text">MIkpoly完整算法实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-Implementation"><span class="nav-text">4	 Implementation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#GPU-%E5%B9%B3%E5%8F%B0"><span class="nav-text">GPU 平台</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#NPU-%E5%B9%B3%E5%8F%B0"><span class="nav-text">NPU 平台</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5Evaluation"><span class="nav-text">5	Evaluation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83"><span class="nav-text">实验环境</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95"><span class="nav-text">基准测试</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95%E6%A0%B7%E4%BE%8B%E9%80%89%E6%8B%A9"><span class="nav-text">测试样例选择</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95%E8%BF%87%E7%A8%8B"><span class="nav-text">测试过程</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%A7%E8%83%BD%E7%BB%93%E6%9E%9C"><span class="nav-text">性能结果</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AF%B9%E5%8A%A8%E6%80%81%E5%BD%A2%E7%8A%B6%E7%AE%97%E5%AD%90%E7%9A%84%E4%BC%98%E5%8C%96%E6%95%88%E6%9E%9C"><span class="nav-text">对动态形状算子的优化效果</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#MIKPOLY-vs-GPU-libraries"><span class="nav-text">MIKPOLY  vs  GPU libraries</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MIKPOLY-vs-NPU-libraries"><span class="nav-text">MIKPOLY  vs  NPU libraries</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AF%B9%E5%8A%A8%E6%80%81%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E7%9A%84%E4%BC%98%E5%8C%96%E6%95%88%E6%9E%9C"><span class="nav-text">对动态模型推理的优化效果</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#GPU%E4%B8%8A%E8%BF%9B%E8%A1%8C%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86"><span class="nav-text">GPU上进行模型推理</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#NPU%E4%B8%8A%E8%BF%9B%E8%A1%8C%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86"><span class="nav-text">NPU上进行模型推理</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Mikpoly%E5%92%8C%E7%8E%B0%E6%9C%89%E6%8A%80%E6%9C%AF%E5%AF%B9%E6%AF%94"><span class="nav-text">Mikpoly和现有技术对比</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B0%86Mikpoly%E5%BA%94%E7%94%A8%E5%88%B0%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BLLM"><span class="nav-text">将Mikpoly应用到大语言模型LLM</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90"><span class="nav-text">性能分析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9C%A8%E7%BA%BF%E8%81%9A%E5%90%88%E5%BC%80%E9%94%80"><span class="nav-text">在线聚合开销</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%88%90%E6%9C%AC%E6%A8%A1%E5%9E%8B%E6%9C%89%E6%95%88%E6%80%A7"><span class="nav-text">成本模型有效性</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%B6%85%E5%8F%82%E6%95%B0%E5%88%86%E6%9E%90"><span class="nav-text">超参数分析</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-Case-Studies"><span class="nav-text">6 	Case Studies</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-Discussion"><span class="nav-text">7	 Discussion</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%9A%E7%94%A8%E6%80%A7"><span class="nav-text">通用性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%82%E7%94%A8%E6%80%A7"><span class="nav-text">适用性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%99%90%E5%88%B6"><span class="nav-text">限制</span></a></li></ol></li></ol></li></ol>
    </div>
</div>

            </div>
        
    </div>
</div>


                
            </div>
        </div>

        <div class="page-main-content-bottom border-box">
            
<footer class="footer border-box">
    <div class="copyright-info info-item">
        &copy;&nbsp;<span>2020</span>&nbsp;-&nbsp;2024
        
            &nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;&nbsp;<a href="/">Lucas-Lxb</a>
        
    </div>

    <div class="theme-info info-item">
        由&nbsp;<a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;驱动&nbsp;&&nbsp;主题&nbsp;<a class="keep-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep</a>
    </div>

    
        
        <div class="deploy-info info-item">
            
            本站由 <span class="tooltip" data-tooltip-content="GitHub Pages"><img src="/images/brands/github.png"></span> 提供部署服务
            
        </div>
    

    

    
</footer>

        </div>
    </div>

    <!-- post tools -->
    
        <div class="post-tools right-toc">
            <div class="post-tools-container border-box">
    <ul class="post-tools-list border-box">
        <!-- PC encrypt again -->
        

        <!-- PC TOC show toggle -->
        
            <li class="tools-item flex-center toggle-show-toc">
                <i class="fas fa-list"></i>
            </li>
        

        <!-- PC go comment -->
        

        <!-- PC full screen -->
        <li class="tools-item flex-center full-screen">
            <i class="fa-solid fa-expand"></i>
        </li>
    </ul>
</div>

        </div>
    

    <!-- side tools -->
    <div class="side-tools">
        <div class="side-tools-container border-box ">
    <ul class="side-tools-list side-tools-show-handle border-box">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <!-- toggle mode -->
        

        <!-- rss -->
        
            <li class="tools-item rss flex-center">
                <a class="flex-center"
                   href="/atom.xml"
                   target="_blank"
                >
                    <i class="fas fa-rss"></i>
                </a>
            </li>
        

        <!-- to bottom -->
        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list border-box">
        
            <li class="tools-item toggle-show-toc-tablet flex-center">
                <i class="fas fa-list"></i>
            </li>
        

        

        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>

        <li class="tools-item tool-scroll-to-top flex-center show-arrow">
            <i class="arrow fas fa-arrow-up"></i>
            <span class="percent"></span>
        </li>
    </ul>
</div>

    </div>

    <!-- image mask -->
    <div class="zoom-in-image-mask">
    <img class="zoom-in-image">
</div>


    <!-- local search -->
    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="搜索..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="close-popup-btn">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

    <!-- tablet toc -->
    
        <div class="tablet-post-toc-mask">
            <div class="tablet-post-toc">
                <div class="post-toc-wrap border-box">
    <div class="post-toc border-box">
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-text">    Optimizing Dynamic-Shape Neural Networks on
Accelerators via On-the-Fly Micro-Kernel
Polymerization </span></a></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-text">   （基于微核聚合的加速器动态形状神经网络优化） </span></a></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-text">一、涉及到的定义</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E8%AE%A1%E7%AE%97%E5%9B%BE"><span class="nav-text">1.计算图</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%89%A7%E8%A1%8C%E4%B8%8E%E5%AE%9A%E4%B9%89%E5%90%88%E4%BA%8C%E4%B8%BA%E4%B8%80%EF%BC%9A"><span class="nav-text">执行与定义合二为一：</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E5%BE%AA%E7%8E%AF%E5%B9%B3%E9%93%BA%E7%BB%93%E6%9E%84"><span class="nav-text">2.循环平铺结构</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-text">二、论文全文内容总结</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Introduction"><span class="nav-text">1 	Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E7%A7%8D%E5%BC%A0%E9%87%8F%E8%AE%A1%E7%AE%97%E7%9A%84%E4%BB%A3%E8%A1%A8%E6%80%A7%E6%96%B9%E6%B3%95"><span class="nav-text">三种张量计算的代表性方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%8E%B0%E6%9C%89%E6%96%B9%E6%B3%95%E5%BC%8A%E7%AB%AF%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="nav-text">现有方法弊端和解决方案</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%AC%E6%96%87%E6%89%80%E5%81%9A%E7%9A%84%E5%B7%A5%E4%BD%9C"><span class="nav-text">本文所做的工作</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2Background-and-Motivation"><span class="nav-text">2	Background and Motivation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%8E%B0%E6%9C%89%E6%8A%80%E6%9C%AF%E8%A7%A3%E5%86%B3%E7%AE%97%E5%AD%90%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-text">现有技术解决算子的实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Mikpoly%E8%A7%A3%E5%86%B3%E7%AE%97%E5%AD%90%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-text">Mikpoly解决算子的实现</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-MikPoly-%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3"><span class="nav-text">(1)MikPoly 的核心思想</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%B5%81%E7%A8%8B"><span class="nav-text">(2)两阶段流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-%E5%BE%AE%E5%86%85%E6%A0%B8%E5%A4%9A%E6%A0%B7%E5%8C%96"><span class="nav-text">(3) 微内核多样化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-%E6%88%90%E6%9C%AC%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-text">(4)成本模型的使用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-%E6%9C%80%E7%BB%88%E6%95%88%E6%9E%9C"><span class="nav-text">(5)最终效果</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3The-MIKPOLY-Design"><span class="nav-text">3	The MIKPOLY Design</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E7%BA%A7%E5%8A%A0%E9%80%9F%E5%99%A8%E6%8A%BD%E8%B1%A1"><span class="nav-text">多级加速器抽象</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%A4%E9%98%B6%E6%AE%B5%E4%BC%98%E5%8C%96"><span class="nav-text">两阶段优化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%A7%A3%E8%80%A6%E4%BC%98%E5%8C%96%E7%A9%BA%E9%97%B4"><span class="nav-text">解耦优化空间</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%A6%BB%E7%BA%BF%E4%BC%98%E5%8C%96%E7%A9%BA%E9%97%B4"><span class="nav-text">离线优化空间</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9C%A8%E7%BA%BF%E4%BC%98%E5%8C%96%E7%A9%BA%E9%97%B4"><span class="nav-text">在线优化空间</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BC%98%E5%8C%96%E7%9B%AE%E6%A0%87"><span class="nav-text">优化目标</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BE%AE%E5%86%85%E6%A0%B8%E7%94%9F%E6%88%90"><span class="nav-text">微内核生成</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%87%AA%E5%8A%A8%E8%B0%83%E6%95%B4%E5%9B%BA%E5%AE%9A%E5%A4%A7%E5%B0%8F%E7%9A%84%E5%BE%AE%E5%86%85%E6%A0%B8"><span class="nav-text">自动调整固定大小的微内核</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%BE%AE%E5%86%85%E6%A0%B8%E6%80%A7%E8%83%BD%E6%A8%A1%E5%9E%8B"><span class="nav-text">微内核性能模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BE%AE%E5%86%85%E6%A0%B8%E8%81%9A%E5%90%88"><span class="nav-text">微内核聚合</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%81%9A%E5%90%88%E6%A8%A1%E5%BC%8F"><span class="nav-text">聚合模式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%81%9A%E5%90%88%E7%AD%96%E7%95%A5"><span class="nav-text">聚合策略</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#image-20241007144016720"><span class="nav-text"></span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%81%9A%E5%90%88%E6%88%90%E6%9C%AC%E6%A8%A1%E5%9E%8B"><span class="nav-text">聚合成本模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MIkpoly%E5%AE%8C%E6%95%B4%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0"><span class="nav-text">MIkpoly完整算法实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-Implementation"><span class="nav-text">4	 Implementation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#GPU-%E5%B9%B3%E5%8F%B0"><span class="nav-text">GPU 平台</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#NPU-%E5%B9%B3%E5%8F%B0"><span class="nav-text">NPU 平台</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5Evaluation"><span class="nav-text">5	Evaluation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83"><span class="nav-text">实验环境</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95"><span class="nav-text">基准测试</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95%E6%A0%B7%E4%BE%8B%E9%80%89%E6%8B%A9"><span class="nav-text">测试样例选择</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95%E8%BF%87%E7%A8%8B"><span class="nav-text">测试过程</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%A7%E8%83%BD%E7%BB%93%E6%9E%9C"><span class="nav-text">性能结果</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AF%B9%E5%8A%A8%E6%80%81%E5%BD%A2%E7%8A%B6%E7%AE%97%E5%AD%90%E7%9A%84%E4%BC%98%E5%8C%96%E6%95%88%E6%9E%9C"><span class="nav-text">对动态形状算子的优化效果</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#MIKPOLY-vs-GPU-libraries"><span class="nav-text">MIKPOLY  vs  GPU libraries</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#MIKPOLY-vs-NPU-libraries"><span class="nav-text">MIKPOLY  vs  NPU libraries</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AF%B9%E5%8A%A8%E6%80%81%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E7%9A%84%E4%BC%98%E5%8C%96%E6%95%88%E6%9E%9C"><span class="nav-text">对动态模型推理的优化效果</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#GPU%E4%B8%8A%E8%BF%9B%E8%A1%8C%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86"><span class="nav-text">GPU上进行模型推理</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#NPU%E4%B8%8A%E8%BF%9B%E8%A1%8C%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86"><span class="nav-text">NPU上进行模型推理</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Mikpoly%E5%92%8C%E7%8E%B0%E6%9C%89%E6%8A%80%E6%9C%AF%E5%AF%B9%E6%AF%94"><span class="nav-text">Mikpoly和现有技术对比</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B0%86Mikpoly%E5%BA%94%E7%94%A8%E5%88%B0%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BLLM"><span class="nav-text">将Mikpoly应用到大语言模型LLM</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90"><span class="nav-text">性能分析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%9C%A8%E7%BA%BF%E8%81%9A%E5%90%88%E5%BC%80%E9%94%80"><span class="nav-text">在线聚合开销</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%88%90%E6%9C%AC%E6%A8%A1%E5%9E%8B%E6%9C%89%E6%95%88%E6%80%A7"><span class="nav-text">成本模型有效性</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%B6%85%E5%8F%82%E6%95%B0%E5%88%86%E6%9E%90"><span class="nav-text">超参数分析</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-Case-Studies"><span class="nav-text">6 	Case Studies</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-Discussion"><span class="nav-text">7	 Discussion</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%9A%E7%94%A8%E6%80%A7"><span class="nav-text">通用性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%82%E7%94%A8%E6%80%A7"><span class="nav-text">适用性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%99%90%E5%88%B6"><span class="nav-text">限制</span></a></li></ol></li></ol></li></ol>
    </div>
</div>

            </div>
        </div>
    
</main>





<!-- common js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.1/js/utils.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.1/js/header-shrink.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.1/js/back2top.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.1/js/toggle-theme.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.1/js/code-block.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.1/js/main.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.1/js/libs/anime.min.js"></script>

<!-- local search -->

    <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.1/js/local-search.min.js"></script>


<!-- lazyload -->

    <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.1/js/lazyload.min.js"></script>


<div class="">
    <!-- home page -->
    

    <!-- post page -->
    
        <!-- post-helper -->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.1/js/post/post-helper.min.js"></script>

        <!-- toc -->
        
            <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.1/js/post/toc.min.js"></script>
        

        <!-- copyright-info -->
        
            <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.1/js/post/copyright-info.min.js"></script>
        

        <!-- share -->
        
            <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-keep/4.2.1/js/post/share.min.js"></script>
        
    

    <!-- categories page -->
    

    <!-- links page -->
    

    <!-- photos page -->
    

    <!-- tools page -->
    
</div>

<!-- mermaid -->


<!-- pjax -->



    
        
    

</body>
</html>
